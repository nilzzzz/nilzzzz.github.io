I"# <h3 id="爬虫简介">爬虫简介</h3>

<p><img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/%E7%88%AC%E8%99%AB%E7%AE%80%E4%BB%8B.png" alt="此处输入图片的描述" />
<img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/%E7%88%AC%E8%99%AB%E7%AE%80%E4%BB%8B2.png" alt="此处输入图片的描述" /></p>
<h3 id="简单爬虫架构">简单爬虫架构</h3>
<p><img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/%E7%88%AC%E8%99%AB%E6%9E%B6%E6%9E%84.png" alt="此处输入图片的描述" /></p>
<h3 id="简单爬虫架构-运行流程">简单爬虫架构-运行流程</h3>
<p><img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="此处输入图片的描述" /></p>
<h3 id="url管理器">URL管理器</h3>
<p>URL管理器：管理待抓取URL集合和已抓取URL集合
–防止重复抓取、防止循环抓取
<img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/URL%E7%AE%A1%E7%90%86%E5%99%A8.png" alt="此处输入图片的描述" />
<img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/url%E7%AE%A1%E7%90%86%E5%99%A8%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F.png" alt="此处输入图片的描述" /></p>
<h3 id="网页下载器">网页下载器</h3>
<p>网页下载器：将互联网上URL对应的网页下载到本地的工具
网页下载器会将URL对应的互联网网页以HTML的形式下载到本地，存储成一个本地文件或内存字符串</p>

<p>Python有哪几种网页下载器？
urllib2–python官方基础模块，支持直接URL下载，支持登录网页的cookie出来、代理处理等
requests–第三方包更强大</p>

<h3 id="网页下载器urllib2">网页下载器–urllib2</h3>
<p>urllib2下载网页方法1：最简洁方法</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib2
#直接请求
response=urllib2.urlopen('http://www.baidu.com')

#获取状态码，如果是200表示获取成功
print response.getcode()

#读取内容
cont=response.read()
</code></pre></div></div>
<p>urllib2下载网页方法2：添加data、http header
<img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/urllib2-2.png" alt="此处输入图片的描述" /></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib2

#创建Request对象
request=urllib2.Request(url)

#添加数据
request.add_data('a','1')

#添加http的header
request.add_header('User-Agent','Mozilla/5.0')

#发送请求获取结果
response=urllib2.urlopen(request)
</code></pre></div></div>

<p>urllib2下载网页方法3：添加特殊情景的处理器
例如：需要cookie
<img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/urllib2-3.png" alt="此处输入图片的描述" /></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib2,cookielib
#创建cookie容器
cj=cookielib.CookieJar()

#创建1个opener
opener=urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))

#给urllib2安装opener
urllib2.install_opener(opener)

#使用带有cookie的urllib2访问网页
response=urllib2.urlopen("http://www.baidu.com/")
</code></pre></div></div>
<h3 id="网页解析器">网页解析器</h3>
<p><img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90%E5%99%A8.png" alt="此处输入图片的描述" />
<img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90%E5%99%A82.png" alt="此处输入图片的描述" />
<img src="https://blog-1258233124.cos.ap-beijing.myqcloud.com/%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90%E5%99%A83.png" alt="此处输入图片的描述" /></p>

<h3 id="网页解析器-beautiful-soup">网页解析器-Beautiful Soup</h3>
<p>Beautiful Soup
–Python第三方库用于从HTML或XML中提取数据
–官网：https://www.crummy.com/software/BeautifulS
<br />oup/bs4/doc/index.zh.html</p>

<p>创建BeautifulSoup对象</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from bs4 import BeautifulSoup
#根据HTML网页字符串创建BeautifulSoup对象
soup=BeautifulSoup(
                  html_doc,             #HTML文档字符串
                  'html.parser'         #HTML解析器
                  from_encoding='utf8'  #HTML文档的编码
)
</code></pre></div></div>
<p>搜索节点(find_all,find)</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>方法：find_all(name,attrs,string)
#查找所有标签为a的节点
soup.find_all('a')

#查找所有标签为a,链接符合/view/123.htm形式的节点
soup.find_all('a',href='/view/123.htm')
soup.find_all('a',href=re.compile(r'/view/\d+\.htm'))

#查找所有标签为div，class为abc，文字为Python的节点
soup.find_all('div',class_='abc',string='Python')
</code></pre></div></div>

<p>访问节点信息</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#得到节点：&lt;a href='1.html'&gt;Python&lt;/a&gt;
#获取查找到的节点的标签名称
node.name
#获取查找到的a节点的href属性
node['href']
#获取查找到的a节点的链接文字
node.get_text()
</code></pre></div></div>

<h3 id="beautifulsoup实例测试">BeautifulSoup实例测试</h3>
<p>测试环境：eclipse+pydev+python2.7
配置中遇到的问题及解决办法：http://blog.csdn.net/xue_changkong<br />
/article/details/46755639</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#coding:utf8
import re
from bs4 import BeautifulSoup
html_doc = """
<span class="nt">&lt;html&gt;&lt;head&gt;&lt;title&gt;</span>The Dormouse's story<span class="nt">&lt;/title&gt;&lt;/head&gt;</span>
<span class="nt">&lt;body&gt;</span>
<span class="nt">&lt;p</span> <span class="na">class=</span><span class="s">"title"</span><span class="nt">&gt;&lt;b&gt;</span>The Dormouse's story<span class="nt">&lt;/b&gt;&lt;/p&gt;</span>

<span class="nt">&lt;p</span> <span class="na">class=</span><span class="s">"story"</span><span class="nt">&gt;</span>Once upon a time there were three little sisters; and their names were
<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://example.com/elsie"</span> <span class="na">class=</span><span class="s">"sister"</span> <span class="na">id=</span><span class="s">"link1"</span><span class="nt">&gt;</span>Elsie<span class="nt">&lt;/a&gt;</span>,
<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://example.com/lacie"</span> <span class="na">class=</span><span class="s">"sister"</span> <span class="na">id=</span><span class="s">"link2"</span><span class="nt">&gt;</span>Lacie<span class="nt">&lt;/a&gt;</span> and
<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://example.com/tillie"</span> <span class="na">class=</span><span class="s">"sister"</span> <span class="na">id=</span><span class="s">"link3"</span><span class="nt">&gt;</span>Tillie<span class="nt">&lt;/a&gt;</span>;
and they lived at the bottom of a well.<span class="nt">&lt;/p&gt;</span>

<span class="nt">&lt;p</span> <span class="na">class=</span><span class="s">"story"</span><span class="nt">&gt;</span>...<span class="nt">&lt;/p&gt;</span>
"""
soup=BeautifulSoup(html_doc,'html.parser',from_encoding='utf8')
print '获取所有的链接'
links=soup.find_all('a')
for link in links:
    print link.name,link['href'],link.get_text()

print '获取lacie的链接'
link_node=soup.find('a',href="http://example.com/lacie")
print link_node.name,link_node['href'],link_node.get_text()

print '正则匹配'
link_node=soup.find('a',href=re.compile(r"ill"))
print link_node.name,link_node['href'],link_node.get_text()

print '获取p段落文字'
p_node=soup.find('p',class_="title")
print p_node.name,p_node.get_text()
</code></pre></div></div>

<p>测试结果：</p>

<blockquote>
  <p>获取所有的链接 a http://example.com/elsie Elsie a http://example.com/lacie
Lacie a http://example.com/tillie Tillie 获取lacie的链接 a
http://example.com/lacie Lacie 正则匹配 a http://example.com/tillie Tillie
获取p段落文字 p The Dormouse’s story</p>
</blockquote>

:ET